# ResNet18-Pruning-Performance
This project compares fine-grained vs. channel-level pruning on ResNet-18 trained on CIFAR-10 at pruning ratios 0.1, 0.3, and 0.5. Fine-grained pruning retains accuracy but lacks structured sparsity, while channel-level pruning improves efficiency but degrades accuracy. The study explores trade-offs between accuracy and computational performance.

---

# **ResNet-18 Pruning Performance Analysis**
**Fine-Grained vs. Channel-Level Pruning on CIFAR-10**

![GitHub Repo Badge](https://img.shields.io/badge/Deep_Learning-Pruning-blue)  
![GitHub Repo Badge](https://img.shields.io/badge/Framework-PyTorch-red)  
![GitHub Repo Badge](https://img.shields.io/badge/Status-Completed-brightgreen)  

## ğŸ“Œ **Project Overview**
This project analyzes **fine-grained pruning** and **channel-level pruning** applied to a **ResNet-18** model trained on the **CIFAR-10 dataset**. The goal is to compare the impact of both pruning strategies on model accuracy and computational efficiency.  

Key findings reveal that:
- **Fine-grained pruning** retains higher accuracy but lacks structured sparsity for hardware acceleration.
- **Channel-level pruning** enables structured sparsity but suffers from larger accuracy degradation.
- **Pruning ratios (0.1, 0.3, 0.5) were tested** to analyze trade-offs between accuracy and efficiency.

---

## ğŸš€ **Project Highlights**
âœ… **Baseline Model Performance:** Trained ResNet-18 on CIFAR-10 for 5 epochs (~80% accuracy).  
âœ… **Fine-Grained Pruning:** Retains up to **80% accuracy** at low pruning ratios but lacks structured sparsity.  
âœ… **Channel-Level Pruning:** More hardware-friendly but causes sharp accuracy drops (e.g., ~10% at 0.5 pruning ratio).  
âœ… **Performance Graphs:** Accuracy vs. Pruning Ratio for both methods.  

---

## ğŸ“‚ **Project Structure**
```
ğŸ“ ResNet18-Pruning-Performance
â”‚â”€â”€ ğŸ“‚ data/                # Dataset (CIFAR-10 downloaded automatically)
â”‚â”€â”€ ğŸ“‚ models/              # Model checkpoint storage
â”‚â”€â”€ ğŸ“‚ results/             # Accuracy vs. Pruning Ratio graphs
â”‚â”€â”€ ğŸ“œ train.py             # Train ResNet-18 model on CIFAR-10
â”‚â”€â”€ ğŸ“œ prune.py             # Apply fine-grained & channel-level pruning
â”‚â”€â”€ ğŸ“œ evaluate.py          # Evaluate model performance
â”‚â”€â”€ ğŸ“œ requirements.txt     # Dependencies (PyTorch, torchvision, numpy, matplotlib)
â”‚â”€â”€ ğŸ“œ README.md            # Project documentation (this file)
```

---

## ğŸ“Š **Results & Observations**
### **1ï¸âƒ£ Baseline Performance**
- **ResNet-18 trained for 5 epochs** on CIFAR-10 reached **~80% accuracy** before pruning.

### **2ï¸âƒ£ Fine-Grained Pruning Results**
| Pruning Ratio | Accuracy (%) |
|--------------|--------------|
| 0.1 (10%)    | ~80% |
| 0.3 (30%)    | ~75%-78% |
| 0.5 (50%)    | ~50%-55% |

- **Key Observation**: Fine-grained pruning maintains accuracy for low pruning ratios but experiences sharp drops at 0.5.

### **3ï¸âƒ£ Channel-Level Pruning Results**
| Pruning Ratio | Accuracy (%) |
|--------------|--------------|
| 0.1 (10%)    | ~40%-45% |
| 0.3 (30%)    | ~20%-25% |
| 0.5 (50%)    | ~10%-15% |

- **Key Observation**: Channel-level pruning significantly reduces accuracy, making it less suitable for accuracy-critical applications.

### **4ï¸âƒ£ Accuracy vs. Pruning Ratio Graph**
![Accuracy vs Pruning Ratio](results/accuracy_vs_pruning.png)

---

## ğŸ›  **Installation & Usage**
### **1ï¸âƒ£ Install Dependencies**
Clone the repository and install the required dependencies.
```bash
git clone https://github.com/Yeshwant-Kasa/ResNet18-Pruning-Performance.git
cd ResNet18-Pruning-Performance
pip install -r requirements.txt
```

### **2ï¸âƒ£ Train the Baseline Model**
Run the training script to train ResNet-18 on CIFAR-10 for 5 epochs.
```bash
python train.py
```

### **3ï¸âƒ£ Apply Pruning**
#### **Fine-Grained Pruning**
```bash
python prune.py --method fine --ratio 0.3
```
#### **Channel-Level Pruning**
```bash
python prune.py --method channel --ratio 0.3
```

### **4ï¸âƒ£ Evaluate Pruned Models**
```bash
python evaluate.py
```

---

## ğŸ” **Key Takeaways**
1. **Fine-Grained Pruning** â†’ Best for **accuracy-sensitive** applications but lacks structured sparsity.  
2. **Channel-Level Pruning** â†’ Best for **resource-limited** devices but sacrifices accuracy.  
3. **Future Work** â†’ Hybrid pruning strategies may balance accuracy and efficiency.

---

## ğŸ“Œ **Future Work**
- ğŸ” **Fine-tuning** post-pruning to recover accuracy.
- âš¡ **Hybrid pruning strategies** (combining fine-grained and channel pruning).
- ğŸ“ˆ **Testing with deeper models** (e.g., ResNet-50, VGG16).
- ğŸš€ **Deployment optimizations** using TensorRT for efficient inference.

---

## ğŸ¤ **Contributing**
Contributions are welcome! If you'd like to improve this project:
1. **Fork the repository**.
2. **Create a new branch** (`feature-branch`).
3. **Commit your changes**.
4. **Submit a pull request**.

---

## ğŸ“œ **License**
This project is licensed under the **MIT License**.

---

## ğŸ‘¨â€ğŸ’» **Author**
ğŸ“Œ **Kasa Yeshwant** â€“ *Sensor Optimization, App Development with Android Studio-Koala, Machine Learning Researcher & AI Enthusiast*  
ğŸ“§ [yeshwantkasa@gmail.com](mailto:your.email@example.com)  
ğŸŒ [GitHub Profile](https://github.com/Yeshwant-Kasa)

---


